{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import packages","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:58:58.194498Z","iopub.execute_input":"2022-12-04T23:58:58.194916Z","iopub.status.idle":"2022-12-04T23:58:58.200564Z","shell.execute_reply.started":"2022-12-04T23:58:58.194875Z","shell.execute_reply":"2022-12-04T23:58:58.199571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\nimport os\nimport cv2\nimport glob\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\ntorch.manual_seed(1102)\nnp.random.seed(1102)\n\ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-04T23:58:58.202672Z","iopub.execute_input":"2022-12-04T23:58:58.203337Z","iopub.status.idle":"2022-12-04T23:59:05.063722Z","shell.execute_reply.started":"2022-12-04T23:58:58.203299Z","shell.execute_reply":"2022-12-04T23:59:05.062679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Download datasets\n#Reference: Downloading technique taken from Assignments 1 and 2.","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:05.065046Z","iopub.execute_input":"2022-12-04T23:59:05.066077Z","iopub.status.idle":"2022-12-04T23:59:05.072705Z","shell.execute_reply.started":"2022-12-04T23:59:05.066039Z","shell.execute_reply":"2022-12-04T23:59:05.071640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/singlecellsegmentation/SingleCellSegmentation/train/image/image_*.png | wc -l\n!ls /kaggle/input/singlecellsegmentation/SingleCellSegmentation/valid/image/image_*.png | wc -l\n!ls /kaggle/input/singlecellsegmentation/SingleCellSegmentation/test/image/image_*.png | wc -l","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:05.078083Z","iopub.execute_input":"2022-12-04T23:59:05.078783Z","iopub.status.idle":"2022-12-04T23:59:20.910828Z","shell.execute_reply.started":"2022-12-04T23:59:05.078746Z","shell.execute_reply":"2022-12-04T23:59:20.909659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DataSets\n#Reference: AoE_BME_Lecture4_PartC_UNetExample_2022","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:20.913127Z","iopub.execute_input":"2022-12-04T23:59:20.913455Z","iopub.status.idle":"2022-12-04T23:59:20.918098Z","shell.execute_reply.started":"2022-12-04T23:59:20.913423Z","shell.execute_reply":"2022-12-04T23:59:20.916931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_root_folder = '../input/singlecellsegmentation/SingleCellSegmentation/'\nclass BasicDataset(TensorDataset):\n    # This function takes folder name ('train', 'valid', 'test') as input and creates an instance of BasicDataset according to that folder.\n    # Also if you'dd like to have less number of samples (for evaluation purposes), you may set the `n_sample` with an integer.\n    def __init__(self, folder, n_sample=None):\n        self.folder = os.path.join(data_root_folder, folder)\n        self.imgs_dir = os.path.join(self.folder, 'image')\n        self.masks_dir = os.path.join(self.folder, 'mask')\n        \n        self.imgs_file = sorted(glob.glob(os.path.join(self.imgs_dir, '*.png')))\n        self.masks_file = sorted(glob.glob(os.path.join(self.masks_dir, '*.png')))\n        \n        assert len(self.imgs_file) == len(self.masks_file), 'There are some missing images or masks in {0}'.format(folder)\n        \n        # If n_sample is not None (It has been set by the user)\n        if not n_sample or n_sample > len(self.imgs_file):\n            n_sample = len(self.imgs_file)\n        \n        self.n_sample = n_sample\n        self.ids = list([i+1 for i in range(n_sample)])\n            \n    def __len__(self):\n        return self.n_sample\n    \n    # This function takes an index (i) which is between 0 to `len(BasicDataset)` (The return of the previous function), then returns RGB image, \n    # mask (Binary), and the index of the file name (Which we will use for visualization). The preprocessing step is also implemented in this function.\n    def __getitem__(self, i):\n        idx = self.ids[i]\n        img = cv2.imread(os.path.join(self.imgs_dir, 'image_{0:04d}.png'.format(idx)), cv2.IMREAD_COLOR)\n        mask = cv2.imread(os.path.join(self.masks_dir, 'mask_{0:04d}.png'.format(idx)), cv2.IMREAD_GRAYSCALE)\n\n        # Convert BGR to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        #Resize all images from 512 to 256 (H and W)\n        img = cv2.resize(img, (256,256))\n        mask = cv2.resize(mask, (256,256))\n        \n        # Scale between 0 to 1\n        img = np.array(img) / 255.0\n        mask = np.array(mask) / 255.0\n        \n        # Make sure that the mask are binary (0 or 1)\n        mask[mask <= 0.5] = 0.0\n        mask[mask > 0.5] = 1.0\n        \n        # Add an axis to the mask array so that it is in [channel, width, height] format.\n        mask = np.expand_dims(mask, axis=0)\n        \n        # HWC to CHW\n        img = np.transpose(img, (2, 0, 1))\n        \n        return {\n            'image': torch.from_numpy(img).type(torch.FloatTensor),\n            'mask': torch.from_numpy(mask).type(torch.FloatTensor),\n            'img_id': idx\n        }","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:20.919504Z","iopub.execute_input":"2022-12-04T23:59:20.919826Z","iopub.status.idle":"2022-12-04T23:59:20.936293Z","shell.execute_reply.started":"2022-12-04T23:59:20.919792Z","shell.execute_reply":"2022-12-04T23:59:20.935301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train, validation, and test dataset instances\ntrain_dataset = BasicDataset('train')\nvalid_dataset = BasicDataset('valid')\ntest_dataset = BasicDataset('test')\n\nplt.figure(figsize=(12,8))\nplt.title('Data split distribution')\nplt.bar(0, len(train_dataset), label='Train')\nplt.bar(1, len(valid_dataset), label='Validation')\nplt.bar(2, len(test_dataset), label='Test')\nplt.ylabel('Number of samples')\nplt.xticks([0,1,2],['Train', 'Validation', 'Test'])\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:20.937562Z","iopub.execute_input":"2022-12-04T23:59:20.937934Z","iopub.status.idle":"2022-12-04T23:59:22.009941Z","shell.execute_reply.started":"2022-12-04T23:59:20.937897Z","shell.execute_reply":"2022-12-04T23:59:22.008818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train, validation, and test dataset instances\ntrain_dataset = BasicDataset('train')\nvalid_dataset = BasicDataset('valid')\ntest_dataset = BasicDataset('test')\n\n# this is EXTRA just demonstrating the BasicDataset\nsample = np.random.randint(0, len(train_dataset))\ndata = train_dataset.__getitem__(sample)\nx = data['image']\ny = data['mask']\nidx = data['img_id']\n\nprint(f'x shape is {x.shape}')\nprint(f'y shape is {y.shape}')\n\nplt.figure(figsize=(12, 8), dpi=100)\nplt.suptitle(f'Sample {idx:04d}')\nimg = np.transpose(x, (1,2,0))\nmask = y[0]\nplt.subplot(1, 2, 1)\nplt.title('Image')\nplt.imshow(img)\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.title('Mask')\nplt.imshow(mask, cmap='gray')\nplt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:22.011564Z","iopub.execute_input":"2022-12-04T23:59:22.011944Z","iopub.status.idle":"2022-12-04T23:59:22.712386Z","shell.execute_reply.started":"2022-12-04T23:59:22.011907Z","shell.execute_reply":"2022-12-04T23:59:22.711544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DataLoader\n#Reference: AoE_BME_Lecture4_PartC_UNetExample_2022","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:22.713329Z","iopub.execute_input":"2022-12-04T23:59:22.713632Z","iopub.status.idle":"2022-12-04T23:59:22.718990Z","shell.execute_reply.started":"2022-12-04T23:59:22.713602Z","shell.execute_reply":"2022-12-04T23:59:22.717719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create data loaders\ntrain_dataset = BasicDataset('train')\nvalid_dataset = BasicDataset('valid')\ntest_dataset = BasicDataset('test')\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=4, num_workers=2, pin_memory=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=4, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:22.724236Z","iopub.execute_input":"2022-12-04T23:59:22.724789Z","iopub.status.idle":"2022-12-04T23:59:22.784559Z","shell.execute_reply.started":"2022-12-04T23:59:22.724758Z","shell.execute_reply":"2022-12-04T23:59:22.783892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#U-Net Architecture\n#Reference: AoE_BME_Lecture4_PartC_UNetExample_2022","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:22.785966Z","iopub.execute_input":"2022-12-04T23:59:22.786598Z","iopub.status.idle":"2022-12-04T23:59:22.790912Z","shell.execute_reply.started":"2022-12-04T23:59:22.786562Z","shell.execute_reply":"2022-12-04T23:59:22.789856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n######################################## Maxpooling followed by Double Convolution\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n    \n######################################## Upsampling followed by Double Convolution\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up_conv = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n        ) \n        self.conv = DoubleConv(out_channels * 2, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up_conv(x1)\n        x = torch.cat([x1, x2], dim=1)\n        x = self.conv(x)\n        return x\n    \n######################################## Output layer (1x1 Convolution followed by SoftMax activation)\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv_sigmoid = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.conv_sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:22.792532Z","iopub.execute_input":"2022-12-04T23:59:22.793419Z","iopub.status.idle":"2022-12-04T23:59:22.807096Z","shell.execute_reply.started":"2022-12-04T23:59:22.793384Z","shell.execute_reply":"2022-12-04T23:59:22.806122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, name, n_channels, n_classes):\n        super(UNet, self).__init__()\n        self.name = name\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n\n        self.inputL = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        self.down4 = Down(512, 1024)\n        self.up1 = Up(1024, 512)\n        self.up2 = Up(512, 256)\n        self.up3 = Up(256, 128)\n        self.up4 = Up(128, 64)\n        self.outputL = OutConv(64, n_classes)\n        \n\n    def forward(self, x):\n        x1 = self.inputL(x)\n        \n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        b = self.down4(x4)\n        \n        x = self.up1(b, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        \n        x = self.outputL(x)\n        \n        return x\n\nmy_UNet = UNet('MyUNet', 3, 1)\nmy_UNet.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:22.808532Z","iopub.execute_input":"2022-12-04T23:59:22.808992Z","iopub.status.idle":"2022-12-04T23:59:28.110873Z","shell.execute_reply.started":"2022-12-04T23:59:22.808949Z","shell.execute_reply":"2022-12-04T23:59:28.109832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loss function and Optimzation Method","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:28.112061Z","iopub.execute_input":"2022-12-04T23:59:28.113275Z","iopub.status.idle":"2022-12-04T23:59:28.118181Z","shell.execute_reply.started":"2022-12-04T23:59:28.113236Z","shell.execute_reply":"2022-12-04T23:59:28.116729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in test_dataloader:\n    sample_batch = batch\n    break\n    \n# Generate network prediction\nwith torch.no_grad():\n    y_pred = my_UNet(sample_batch['image'].cuda())\n\n# Print the shapes of the images, masks, predicted masks\nprint('Sample batch \\'image \\'shape is: {0}\\nSample batch \\'mask\\' shape is: {1}\\nPredicted mask shape is: {2}'.format(sample_batch['image'].shape,sample_batch['mask'].shape,y_pred.shape))\n\n# Conver Pytorch tensor to numpy array then reverse the preprocessing steps\nimg = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\nmsk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n\n# Exctract the relative prediction mask and threshold the probablities (>0.5)\npred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\npred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n\n# Take the image id for display\nimg_id = sample_batch['img_id'][0]\n\n# Plot the smaple, ground truth, the prediction probability map, and the final predicted mask\nplt.figure(figsize=(20,16))\nplt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n\nplt.subplot(2,4,1)\nplt.title('Input Image', fontsize=15)\nplt.imshow(img)\nplt.axis('off')\n\nplt.subplot(2,4,2)\nplt.title('Ground Truth', fontsize=15)\nplt.imshow(msk, cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,4,3)\nplt.title('Non-trained Network Prediction Output \\n(probability [0, 1])', fontsize=15)\nplt.imshow(pred_msk, cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,4,4)\nplt.title('Non-trained Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\nplt.imshow(pred_msk_binary, cmap='gray')\nplt.axis('off')\n\ninput_overlayed_GT = img.copy()\ninput_overlayed_GT[msk == 255, :] = [0, 255, 0]\nplt.subplot(2,4,5)\nplt.title('Input Image overlayed with Ground Truth', fontsize=15)\nplt.imshow(input_overlayed_GT)\nplt.axis('off')\n\ninput_overlayed_Pred = img.copy()\ninput_overlayed_Pred[pred_msk_binary == 255, :] = [255, 0, 0]\nplt.subplot(2,4,6)\nplt.title('Input Image overlayed with Prediction', fontsize=15)\nplt.imshow(input_overlayed_Pred)\nplt.axis('off')\n\nGT_overlayed_prediction = np.zeros_like(img)\nGT_overlayed_prediction[msk == 255, 1] = 255\nGT_overlayed_prediction[pred_msk_binary == 255, 0] = 255\nplt.subplot(2,4,7)\nplt.title('Ground Truth overlayed with Prediction', fontsize=15)\nplt.imshow(GT_overlayed_prediction)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:28.120027Z","iopub.execute_input":"2022-12-04T23:59:28.120815Z","iopub.status.idle":"2022-12-04T23:59:34.886612Z","shell.execute_reply.started":"2022-12-04T23:59:28.120778Z","shell.execute_reply":"2022-12-04T23:59:34.885590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model trained to 50 epochs","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:34.888405Z","iopub.execute_input":"2022-12-04T23:59:34.889003Z","iopub.status.idle":"2022-12-04T23:59:34.893385Z","shell.execute_reply.started":"2022-12-04T23:59:34.888962Z","shell.execute_reply":"2022-12-04T23:59:34.892321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validate model","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:34.895456Z","iopub.execute_input":"2022-12-04T23:59:34.896219Z","iopub.status.idle":"2022-12-04T23:59:34.903933Z","shell.execute_reply.started":"2022-12-04T23:59:34.896185Z","shell.execute_reply":"2022-12-04T23:59:34.902763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(my_UNet.parameters(), lr=0.001)\nloss_function = nn.BCELoss()\n\n# Define a function that computes the DICE score for binary segmentation\ndef dice_coeff_binary(y_pred, y_true):\n        \"\"\"Values must be only zero or one.\"\"\"\n        eps = 0.0001\n        inter = torch.dot(y_pred.view(-1), y_true.view(-1))\n        union = torch.sum(y_pred) + torch.sum(y_true)\n        return ((2 * inter.float() + eps) / (union.float() + eps)).cpu().numpy()\n    \n\n# The training function\ndef train_net(net, epochs, train_dataloader, valid_dataloader, optimizer, loss_function):\n    \n    if not os.path.isdir('{0}'.format(net.name)):\n        os.mkdir('{0}'.format(net.name))\n    \n    n_train = len(train_dataloader)\n    n_valid = len(valid_dataloader)    \n    \n    train_loss = list()\n    valid_loss = list()\n    train_dice = list()\n    valid_dice = list()\n    \n    for epoch in range(epochs):\n        \n        ################################################################################################################################\n        ########################################################### Training ###########################################################\n        ################################################################################################################################\n        \n        net.train()\n        train_batch_loss = list()\n        train_batch_dice = list()\n        \n        for i, batch in enumerate(train_dataloader):\n\n            # Load a batch and pass it to the GPU\n            imgs = batch['image'].cuda()\n            true_masks = batch['mask'].cuda()\n\n            # Produce the estimated mask using current weights\n            y_pred = net(imgs)\n\n            # Compute the loss for this batch and append it to the epoch loss\n            loss = loss_function(y_pred, true_masks)\n            batch_loss = loss.item()\n            train_batch_loss.append(batch_loss)\n\n            # Make the thresholded mask to compute the DICE score\n            pred_binary = (y_pred > 0.5).float()                    # You can change the probablity threshold!\n            \n            # Compute the DICE score for this batch and append it to the epoch dice\n            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n            train_batch_dice.append(batch_dice_score)\n            \n            # Reset gradient values\n            optimizer.zero_grad()\n\n            # Compute the backward losses\n            loss.backward()\n\n            # Update the weights\n            optimizer.step()\n            \n            # Print the progress\n            print(f'EPOCH {epoch + 1}/{epochs} - Training Batch {i+1}/{n_train} - Loss: {batch_loss}, DICE score: {batch_dice_score}', end='\\r')\n        \n        average_training_loss = np.array(train_batch_loss).mean()\n        average_training_dice = np.array(train_batch_dice).mean()\n        train_loss.append(average_training_loss)\n        train_dice.append(average_training_dice)\n        \n        ################################################################################################################################\n        ########################################################## Validation ##########################################################\n        ################################################################################################################################\n        \n        net.eval()\n        valid_batch_loss = list()\n        valid_batch_dice = list()\n        \n        # This part is almost the same as training with the difference that we will set all layers to evaluation mode (effects some layers such as BN and Dropout) and also\n        # we don't need to calculate the gradient since we are only evaluating current state of the model. This will speed up the process and cause it to consume less memory.\n        with torch.no_grad():\n            for i, batch in enumerate(valid_dataloader):\n\n                # Load a batch and pass it to the GPU\n                imgs = batch['image'].cuda()\n                true_masks = batch['mask'].cuda()\n\n                # Produce the estimated mask using current weights\n                y_pred = net(imgs)\n\n                # Compute the loss for this batch and append it to the epoch loss\n                loss = loss_function(y_pred, true_masks)\n                batch_loss = loss.item()\n                valid_batch_loss.append(batch_loss)\n\n                # Make the thresholded mask to compute the DICE score\n                pred_binary = (y_pred > 0.5).float()                    # You can change the probablity threshold!\n\n                # Compute the DICE score for this batch and append it to the epoch dice\n                batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n                valid_batch_dice.append(batch_dice_score)\n\n                # Print the progress\n                print(f'EPOCH {epoch + 1}/{epochs} - Validation Batch {i+1}/{n_valid} - Loss: {batch_loss}, DICE score: {batch_dice_score}', end='\\r')\n                \n        average_validation_loss = np.array(valid_batch_loss).mean()\n        average_validation_dice = np.array(valid_batch_dice).mean()\n        valid_loss.append(average_validation_loss)\n        valid_dice.append(average_validation_dice)\n        \n        \n        print(f'EPOCH {epoch + 1}/{epochs} - Training Loss: {average_training_loss}, Training DICE score: {average_training_dice}, Validation Loss: {average_validation_loss}, Validation DICE score: {average_validation_dice}')\n\n        ################################################################################################################################\n        ###################################################### Saving Checkpoints #####################################################\n        ################################################################################################################################\n        torch.save(net.state_dict(), f'{net.name}/epoch_{epoch+1:03}.pth')\n    \n    return train_loss, train_dice, valid_loss, valid_dice\n\nEPOCHS = 50\ntrain_loss, train_dice, valid_loss, valid_dice = train_net(my_UNet, EPOCHS, train_dataloader, valid_dataloader, optimizer, loss_function)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T23:59:34.905652Z","iopub.execute_input":"2022-12-04T23:59:34.906393Z","iopub.status.idle":"2022-12-05T02:26:04.290116Z","shell.execute_reply.started":"2022-12-04T23:59:34.906360Z","shell.execute_reply":"2022-12-05T02:26:04.288941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Displaying results\n#Reference: AoE_BME_Lecture4_PartC_UNetExample_2022","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:04.292366Z","iopub.execute_input":"2022-12-05T02:26:04.293534Z","iopub.status.idle":"2022-12-05T02:26:04.298369Z","shell.execute_reply.started":"2022-12-05T02:26:04.293478Z","shell.execute_reply":"2022-12-05T02:26:04.297349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.suptitle('Learning Curve', fontsize=18)\n\nplt.subplot(1,2,1)\nplt.plot(np.arange(EPOCHS)+1, train_loss, '-o', label='Training Loss')\nplt.plot(np.arange(EPOCHS)+1, valid_loss, '-o', label='Validation Loss')\nplt.xticks(np.arange(EPOCHS)+1)\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('Loss', fontsize=15)\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(np.arange(EPOCHS)+1, train_dice, '-o', label='Training DICE score')\nplt.plot(np.arange(EPOCHS)+1, valid_dice, '-o', label='Validation DICE score')\nplt.xticks(np.arange(EPOCHS)+1)\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('DICE score', fontsize=15)\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:04.300047Z","iopub.execute_input":"2022-12-05T02:26:04.300395Z","iopub.status.idle":"2022-12-05T02:26:05.319663Z","shell.execute_reply.started":"2022-12-05T02:26:04.300361Z","shell.execute_reply":"2022-12-05T02:26:05.318760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Best epoch and load","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:05.321228Z","iopub.execute_input":"2022-12-05T02:26:05.321971Z","iopub.status.idle":"2022-12-05T02:26:05.326539Z","shell.execute_reply.started":"2022-12-05T02:26:05.321928Z","shell.execute_reply":"2022-12-05T02:26:05.325380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_epoch = np.argmax(valid_dice) + 1 # The plus one is because the epochs starts at 1.\n\nprint(f'Best epoch is epoch{best_epoch}')\n\nstate_dict = torch.load(f'./MyUNet/epoch_{best_epoch:03}.pth')\n\nmy_UNet.load_state_dict(state_dict)\nmy_UNet.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:05.328213Z","iopub.execute_input":"2022-12-05T02:26:05.328581Z","iopub.status.idle":"2022-12-05T02:26:05.444098Z","shell.execute_reply.started":"2022-12-05T02:26:05.328546Z","shell.execute_reply":"2022-12-05T02:26:05.443093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take the first batch\nfor batch in test_dataloader:\n    sample_batch = batch\n    break\n    \n# Generate network prediction\nwith torch.no_grad():\n    y_pred = my_UNet(sample_batch['image'].cuda())\n\n# Print the shapes of the images, masks, predicted masks\nprint('Sample batch \\'image \\'shape is: {0}\\nSample batch \\'mask\\' shape is: {1}\\nPredicted mask shape is: {2}'.format(sample_batch['image'].shape,sample_batch['mask'].shape,y_pred.shape))\n\n# Conver Pytorch tensor to numpy array then reverse the preprocessing steps\nimg = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\nmsk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n\n# Exctract the relative prediction mask and threshold the probablities (>0.5)\npred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\npred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n\n# Take the image id for display\nimg_id = sample_batch['img_id'][0]\n\n# Plot the smaple, ground truth, the prediction probability map, and the final predicted mask\nplt.figure(figsize=(24,18))\nplt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n\nplt.subplot(2,4,1)\nplt.title('Input Image', fontsize=15)\nplt.imshow(img)\nplt.axis('off')\n\nplt.subplot(2,4,2)\nplt.title('Ground Truth', fontsize=15)\nplt.imshow(msk, cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,4,3)\nplt.title('Final Network Prediction Output \\n(probability [0, 1])', fontsize=15)\nplt.imshow(pred_msk, cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,4,4)\nplt.title('Final Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\nplt.imshow(pred_msk_binary, cmap='gray')\nplt.axis('off')\n\ninput_overlayed_GT = img.copy()\ninput_overlayed_GT[msk == 255, :] = [0, 255, 0]\nplt.subplot(2,4,5)\nplt.title('Input Image overlayed with Ground Truth', fontsize=15)\nplt.imshow(input_overlayed_GT)\nplt.axis('off')\n\ninput_overlayed_Pred = img.copy()\ninput_overlayed_Pred[pred_msk_binary == 255, :] = [255, 0, 0]\nplt.subplot(2,4,6)\nplt.title('Input Image overlayed with Prediction', fontsize=15)\nplt.imshow(input_overlayed_Pred)\nplt.axis('off')\n\nGT_overlayed_prediction = np.zeros_like(img)\nGT_overlayed_prediction[msk == 255, 1] = 255\nGT_overlayed_prediction[pred_msk_binary == 255, 0] = 255\nplt.subplot(2,4,7)\nplt.title('Ground Truth overlayed with Prediction', fontsize=15)\nplt.imshow(GT_overlayed_prediction)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:05.445821Z","iopub.execute_input":"2022-12-05T02:26:05.446518Z","iopub.status.idle":"2022-12-05T02:26:06.907581Z","shell.execute_reply.started":"2022-12-05T02:26:05.446481Z","shell.execute_reply":"2022-12-05T02:26:06.906605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test model","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:06.909134Z","iopub.execute_input":"2022-12-05T02:26:06.909761Z","iopub.status.idle":"2022-12-05T02:26:06.918600Z","shell.execute_reply.started":"2022-12-05T02:26:06.909717Z","shell.execute_reply":"2022-12-05T02:26:06.913745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_net(net, test_dataloader, loss_function):\n    # Create the pred_mask folder\n    if not os.path.isdir('/kaggle/working/pred_mask'):\n        os.mkdir('/kaggle/working/pred_mask')\n    \n    net.eval()\n    \n    n_test = len(test_dataloader)\n    test_batch_loss = list()\n    test_batch_dice = list()\n    test_batch_accuray = list()\n    test_batch_CM = list()\n\n    # This part is almost the same as the validation loop in `train_net` function. \n    # The difference is that we will calculate the accuracy and confusion matrix per each batch and save the predicted images.\n    with torch.no_grad():\n        for i, batch in enumerate(test_dataloader):\n\n            # Load a batch and pass it to the GPU\n            imgs = batch['image'].cuda()\n            true_masks = batch['mask'].cuda()\n            img_ids = batch['img_id'].numpy().astype('int')\n\n            # Produce the estimated mask using current weights\n            y_pred = net(imgs)\n            \n            # Compute the loss for this batch and append it to the epoch loss\n            loss = loss_function(y_pred, true_masks)\n            batch_loss = loss.item()\n            test_batch_loss.append(batch_loss)\n\n            # Make the thresholded mask to compute the DICE score\n            pred_binary = (y_pred > 0.5).float()                    # You can change the probablity threshold!\n\n            # Compute the DICE score for this batch and append it to the epoch dice\n            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n            test_batch_dice.append(batch_dice_score)\n            \n            # Save the predicted masks\n            for idx, pred_msk in enumerate(pred_binary):\n                cv2.imwrite(f'/kaggle/working/pred_mask/pred_mask_{img_ids[idx]:04}.png', np.expand_dims((pred_msk[0].cpu().numpy() * 255).astype('uint8'), axis=-1))\n            \n            # Vectorize the true mask and predicted mask for this batch\n            vectorize_true_masks = true_masks.view(-1).cpu().numpy()\n            vectorize_pred_masks = pred_binary.view(-1).cpu().numpy()\n            \n            # Compute the accuracy for this batch and append to the overall list\n            batch_accuracy = accuracy_score(vectorize_true_masks, vectorize_pred_masks)\n            test_batch_accuray.append(batch_accuracy)\n            \n            # Compute the normalized confusion matrix for this batch and append to the overall list\n            batch_CM = confusion_matrix(vectorize_true_masks, vectorize_pred_masks, normalize='true', labels=[0, 1])\n            test_batch_CM.append(batch_CM)\n\n            # Print the progress\n            print(f'Test Batch {i+1}/{n_test} - Loss: {batch_loss}, DICE score: {batch_dice_score}, Accuracy: {batch_accuracy}', end='\\r')\n\n    test_loss = np.array(test_batch_loss).mean()\n    test_dice = np.array(test_batch_dice).mean()\n    test_accuracy = np.array(test_batch_accuray).mean()\n    test_CM = np.array(test_batch_CM).mean(axis=0)\n    \n    return test_loss, test_dice, test_accuracy, test_CM\n\ntest_loss, test_dice, test_accuracy, test_CM = test_net(my_UNet, test_dataloader, loss_function)\n\nprint(f'Test Loss: {test_loss}, Test DICE score: {test_dice}, Test overall accuracy: {test_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:26:06.921808Z","iopub.execute_input":"2022-12-05T02:26:06.923607Z","iopub.status.idle":"2022-12-05T02:27:11.443698Z","shell.execute_reply.started":"2022-12-05T02:26:06.923570Z","shell.execute_reply":"2022-12-05T02:27:11.442574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cm = pd.DataFrame(test_CM, index = ['Background', 'Cell'],\n                     columns = ['Background', 'Cell'])\nplt.figure(figsize = (12,10))\nplt.title('Confusion matrix')\nsns.heatmap(df_cm, annot = True, fmt='.2%', annot_kws = {\"size\": 15})\nplt.ylim([0, 2]);\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');","metadata":{"execution":{"iopub.status.busy":"2022-12-05T02:27:11.445309Z","iopub.execute_input":"2022-12-05T02:27:11.445708Z","iopub.status.idle":"2022-12-05T02:27:11.743653Z","shell.execute_reply.started":"2022-12-05T02:27:11.445665Z","shell.execute_reply":"2022-12-05T02:27:11.742467Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
